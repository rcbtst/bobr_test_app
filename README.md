## Как запустить

1. `cp env.example .env`
2. `docker-compose up`

## Алгоритмы работы

1. FastAPI эндпоинт получает запрос на POST /task и создаёт новый Task в бд (PostgreSQL) с пометкой `dispatched=False`

2. Celery Beat периодически проверят таблицу с Task и берёт оттуда записи где `dispatched=False`, отправляет их в
   очередь и помечает их как `dispatched=True` (паттерн Outbox)

3. Celery Worker получает из очередь задачи и выполняет их

## Ответы на вопросы

**1. Почему вы выбрали RabbitMQ или Kafka**

Выбрал RabbitMQ так как был небольшой опыт работы с ним

**2. Как бы вы масштабировали это решение**

- Вынес celery beat в отдельный сервис, хранить schedule не в файле (как это сейчас по умолчанию), а, например, в бд или
  Redis
- Увеличить кол-во celery worker по необходимости
- Увеличить кол-во rabbit mq nodes по необходимости
- Возможно реплики бд
- Возможно больше инстансов fastapi и load balancer

**3. Какие потенциальные точки отказа есть в текущей архитектуре**

- Возможны доставки в очередь задач более одного раза
- Возможно что задача зависнет в статусе Processing, если в ходе всех retry не получится её обработать

**4. Что бы вы улучшили, если бы это был продакшен**

- Добавил какую-то реализацию Lock чтобы избежать дубликатов задач (например, через дополнительные поля в таблице или
  Redis)
- Добавил дополнительно обработку в случаях если в ходе всех Retry не удасться выполнить задачу (например, отправлять в
  этом случае задачу в Dead Letter Queue, а оттуда брать её и помечать как FAILED)
- Добавить тесты
- Более аккуратный код, аккуратнее структура папок, улучшить обработку исключений
